{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duzWxTKcdt-D"
      },
      "source": [
        "# ***Step 1: Data Exploration, EDA, and Visualization***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC2OYxUldt-E",
        "outputId": "28b70fd6-014b-4a59-b57b-05bc5917d87e"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set visualization style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('Car Data.csv')\n",
        "print(f\"Dataset Shape: {df.shape}\")\n",
        "print(f\"\\nDataset Info:\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "yT8NdD0Fdt-F",
        "outputId": "0efd8806-d150-498a-eda6-45f700c54529"
      },
      "outputs": [],
      "source": [
        "# Display first few rows\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "display(df.head())\n",
        "\n",
        "print(\"\\nBasic Statistics:\")\n",
        "display(df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "JsZtGOIFdt-G",
        "outputId": "2141ef16-f423-41ce-82ed-11d324dfd92e"
      },
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "print(\"Missing Values Analysis:\")\n",
        "missing_data = df.isnull().sum()\n",
        "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Values': missing_data,\n",
        "    'Percentage': missing_percent\n",
        "})\n",
        "missing_df = missing_df[missing_df['Missing Values'] > 0]\n",
        "if len(missing_df) > 0:\n",
        "    display(missing_df)\n",
        "else:\n",
        "    print(\"No missing values found!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TNmE6ICdt-G",
        "outputId": "8c343993-fc90-4ef9-adf3-a39e243e95cb"
      },
      "outputs": [],
      "source": [
        "# Check for duplicates\n",
        "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpy9C_EZdt-G",
        "outputId": "e1a4ca9e-9f57-41ef-bb09-79f11bd505cc"
      },
      "outputs": [],
      "source": [
        "# Unique values in categorical columns\n",
        "categorical_cols = ['class', 'drive', 'fuel_type', 'make', 'model', 'transmission']\n",
        "print(\"Unique values in categorical columns:\")\n",
        "for col in categorical_cols:\n",
        "    print(f\"\\n{col}: {df[col].nunique()} unique values\")\n",
        "    print(f\"Top 10 values: {df[col].value_counts().head(10).index.tolist()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iBIPl6l4dt-G",
        "outputId": "012416f1-f259-4f19-e7f5-698910053fcd"
      },
      "outputs": [],
      "source": [
        "# Correlation Analysis (for numerical features)\n",
        "numerical_cols = ['city_mpg', 'combination_mpg', 'cylinders', 'displacement', 'highway_mpg', 'year']\n",
        "correlation_matrix = df[numerical_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
        "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "0WqBOaTddt-H",
        "outputId": "03f27dbd-9595-422d-9830-e27baf3f6614"
      },
      "outputs": [],
      "source": [
        "# Distribution of target variable (combination_mpg)\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Histogram with KDE\n",
        "sns.histplot(df['combination_mpg'], kde=True, ax=axes[0], bins=30)\n",
        "axes[0].axvline(df['combination_mpg'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"combination_mpg\"].mean():.2f}')\n",
        "axes[0].axvline(df['combination_mpg'].median(), color='green', linestyle='--', label=f'Median: {df[\"combination_mpg\"].median():.2f}')\n",
        "axes[0].set_xlabel('Combination MPG')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].legend()\n",
        "\n",
        "# Box plot\n",
        "sns.boxplot(y=df['combination_mpg'], ax=axes[1])\n",
        "axes[1].set_ylabel('Combination MPG')\n",
        "\n",
        "# Q-Q plot\n",
        "stats.probplot(df['combination_mpg'], dist=\"norm\", plot=axes[2])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistical summary of target\n",
        "print(\"Target Variable (combination_mpg) Statistics:\")\n",
        "print(f\"Mean: {df['combination_mpg'].mean():.2f}\")\n",
        "print(f\"Median: {df['combination_mpg'].median():.2f}\")\n",
        "print(f\"Std: {df['combination_mpg'].std():.2f}\")\n",
        "print(f\"Skewness: {df['combination_mpg'].skew():.2f}\")\n",
        "print(f\"Kurtosis: {df['combination_mpg'].kurtosis():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "id": "V0crlJ5Gdt-H",
        "outputId": "4ca99b18-19fd-44f6-912d-fd0bfca887ce"
      },
      "outputs": [],
      "source": [
        "# Time series analysis by year\n",
        "yearly_stats = df.groupby('year').agg({\n",
        "    'combination_mpg': ['mean', 'median', 'std', 'count']\n",
        "}).round(2)\n",
        "yearly_stats.columns = ['Mean_MPG', 'Median_MPG', 'Std_MPG', 'Count']\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Mean MPG over years\n",
        "axes[0, 0].plot(yearly_stats.index, yearly_stats['Mean_MPG'], marker='o', linewidth=2, markersize=8)\n",
        "axes[0, 0].fill_between(yearly_stats.index,\n",
        "                        yearly_stats['Mean_MPG'] - yearly_stats['Std_MPG'],\n",
        "                        yearly_stats['Mean_MPG'] + yearly_stats['Std_MPG'], alpha=0.2)\n",
        "axes[0, 0].set_xlabel('Year')\n",
        "axes[0, 0].set_ylabel('Mean Combination MPG')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Number of models per year\n",
        "axes[0, 1].bar(yearly_stats.index, yearly_stats['Count'], color='steelblue', alpha=0.7)\n",
        "axes[0, 1].set_xlabel('Year')\n",
        "axes[0, 1].set_ylabel('Count')\n",
        "for i, v in enumerate(yearly_stats['Count']):\n",
        "    axes[0, 1].text(yearly_stats.index[i], v + 1, str(int(v)), ha='center', va='bottom')\n",
        "\n",
        "# Box plot of MPG by year\n",
        "sns.boxplot(x='year', y='combination_mpg', data=df, ax=axes[1, 0])\n",
        "axes[1, 0].set_xlabel('Year')\n",
        "axes[1, 0].set_ylabel('Combination MPG')\n",
        "axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Heatmap of MPG distribution by year\n",
        "yearly_pivot = pd.pivot_table(df, values='combination_mpg',\n",
        "                               index=pd.cut(df['combination_mpg'], bins=10),\n",
        "                               columns='year', aggfunc='count')\n",
        "sns.heatmap(yearly_pivot, cmap='YlOrRd', annot=False, fmt='g', ax=axes[1, 1])\n",
        "axes[1, 1].set_xlabel('Year')\n",
        "axes[1, 1].set_ylabel('MPG Bins')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "teksS62zdt-H",
        "outputId": "4fad92c0-512a-45e6-ebd1-39cd417cce98"
      },
      "outputs": [],
      "source": [
        "# Categorical feature analysis\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# 1. Class distribution\n",
        "class_order = df['class'].value_counts().index\n",
        "sns.boxplot(x='class', y='combination_mpg', data=df, ax=axes[0, 0], order=class_order)\n",
        "axes[0, 0].set_xlabel('Vehicle Class')\n",
        "axes[0, 0].set_ylabel('Combination MPG')\n",
        "axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 2. Drive type analysis\n",
        "drive_order = df['drive'].value_counts().index\n",
        "sns.boxplot(x='drive', y='combination_mpg', data=df, ax=axes[0, 1], order=drive_order)\n",
        "axes[0, 1].set_xlabel('Drive Type')\n",
        "axes[0, 1].set_ylabel('Combination MPG')\n",
        "\n",
        "# 3. Fuel type analysis\n",
        "fuel_order = df['fuel_type'].value_counts().index\n",
        "sns.boxplot(x='fuel_type', y='combination_mpg', data=df, ax=axes[0, 2], order=fuel_order)\n",
        "axes[0, 2].set_xlabel('Fuel Type')\n",
        "axes[0, 2].set_ylabel('Combination MPG')\n",
        "\n",
        "# 4. Transmission analysis\n",
        "trans_order = df['transmission'].value_counts().index\n",
        "sns.boxplot(x='transmission', y='combination_mpg', data=df, ax=axes[1, 0], order=trans_order)\n",
        "axes[1, 0].set_xlabel('Transmission')\n",
        "axes[1, 0].set_ylabel('Combination MPG')\n",
        "\n",
        "# 5. Top 15 manufacturers\n",
        "top_makes = df['make'].value_counts().head(15).index\n",
        "sns.boxplot(x='make', y='combination_mpg', data=df[df['make'].isin(top_makes)], ax=axes[1, 1])\n",
        "axes[1, 1].set_xlabel('Manufacturer')\n",
        "axes[1, 1].set_ylabel('Combination MPG')\n",
        "axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 6. Cylinders analysis\n",
        "cyl_order = sorted(df['cylinders'].dropna().unique())\n",
        "sns.boxplot(x='cylinders', y='combination_mpg', data=df, ax=axes[1, 2], order=cyl_order)\n",
        "axes[1, 2].set_xlabel('Number of Cylinders')\n",
        "axes[1, 2].set_ylabel('Combination MPG')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BVkv-ddRdt-I",
        "outputId": "5d7d3728-a480-4313-e51a-4920517b69f1"
      },
      "outputs": [],
      "source": [
        "# Advanced visualization: 3D scatter plot for key features\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "fig = plt.figure(figsize=(14, 10))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# Color by fuel type\n",
        "colors = {'gas': 'red', 'diesel': 'blue', 'electricity': 'green'}\n",
        "color_list = [colors.get(ft, 'gray') for ft in df['fuel_type']]\n",
        "\n",
        "scatter = ax.scatter(df['displacement'], df['cylinders'], df['combination_mpg'],\n",
        "                     c=color_list, s=df['combination_mpg']/2, alpha=0.6, depthshade=True)\n",
        "\n",
        "ax.set_xlabel('Displacement (L)', fontsize=12, labelpad=10)\n",
        "ax.set_ylabel('Cylinders', fontsize=12, labelpad=10)\n",
        "ax.set_zlabel('Combination MPG', fontsize=12, labelpad=10)\n",
        "\n",
        "# Create legend\n",
        "legend_elements = [plt.Line2D([0], [0], marker='o', color='w',\n",
        "                              markerfacecolor=colors['gas'], markersize=10, label='Gas'),\n",
        "                   plt.Line2D([0], [0], marker='o', color='w',\n",
        "                              markerfacecolor=colors['diesel'], markersize=10, label='Diesel'),\n",
        "                   plt.Line2D([0], [0], marker='o', color='w',\n",
        "                              markerfacecolor=colors['electricity'], markersize=10, label='Electric')]\n",
        "ax.legend(handles=legend_elements, loc='upper left', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "temwgfdSdt-I",
        "outputId": "73e5fb5f-76de-4511-bf16-43299530a78d"
      },
      "outputs": [],
      "source": [
        "# Pairplot for numerical features (sampled for clarity)\n",
        "numerical_subset = df[numerical_cols].sample(n=500, random_state=42)  # Sample for clarity\n",
        "g = sns.pairplot(numerical_subset, diag_kind='kde', plot_kws={'alpha': 0.6})\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "dSUSP-wHdt-I",
        "outputId": "a4b69191-f8f2-4eac-a8cd-669773957d51"
      },
      "outputs": [],
      "source": [
        "# Outlier detection using IQR method\n",
        "Q1 = df['combination_mpg'].quantile(0.25)\n",
        "Q3 = df['combination_mpg'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "outliers = df[(df['combination_mpg'] < lower_bound) | (df['combination_mpg'] > upper_bound)]\n",
        "print(f\"Number of outliers in combination_mpg (IQR method): {len(outliers)}\")\n",
        "print(f\"Percentage of outliers: {(len(outliers)/len(df))*100:.2f}%\")\n",
        "\n",
        "if len(outliers) > 0:\n",
        "    print(\"\\nOutlier samples:\")\n",
        "    display(outliers[['make', 'model', 'year', 'combination_mpg']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NotO-ouKdt-I"
      },
      "source": [
        "# ***Step 2: Data Pre-processing***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcN2YCIOdt-I",
        "outputId": "3fbca7d1-e7c7-47d9-cf08-360547ba5083"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Create a copy of the original dataframe for preprocessing\n",
        "df_processed = df.copy()\n",
        "\n",
        "# 1. Handle missing values\n",
        "print(\"Checking for missing values...\")\n",
        "missing_cols = df_processed.columns[df_processed.isnull().any()].tolist()\n",
        "if missing_cols:\n",
        "    print(f\"Columns with missing values: {missing_cols}\")\n",
        "\n",
        "    # For numerical columns, use median imputation (robust to outliers)\n",
        "    numerical_missing = [col for col in missing_cols if df_processed[col].dtype in ['int64', 'float64']]\n",
        "    if numerical_missing:\n",
        "        print(f\"Numerical columns with missing values: {numerical_missing}\")\n",
        "        imputer = SimpleImputer(strategy='median')\n",
        "        df_processed[numerical_missing] = imputer.fit_transform(df_processed[numerical_missing])\n",
        "\n",
        "    # For categorical columns, use most frequent imputation\n",
        "    categorical_missing = [col for col in missing_cols if df_processed[col].dtype == 'object']\n",
        "    if categorical_missing:\n",
        "        print(f\"Categorical columns with missing values: {categorical_missing}\")\n",
        "        imputer = SimpleImputer(strategy='most_frequent')\n",
        "        df_processed[categorical_missing] = imputer.fit_transform(df_processed[categorical_missing])\n",
        "else:\n",
        "    print(\"No missing values found!\")\n",
        "\n",
        "##################### 2. Feature engineering - create new features before splitting\n",
        "print(\"\\nCreating new features...\")\n",
        "\n",
        "# Create engine power-to-weight ratio (approximation)\n",
        "df_processed['power_to_weight'] = df_processed['displacement'] / (df_processed['cylinders'] + 0.1)\n",
        "\n",
        "# Create age feature (from 2024 as current year)\n",
        "df_processed['car_age'] = 2024 - df_processed['year']\n",
        "\n",
        "# Create efficiency ratio between city and highway\n",
        "df_processed['city_highway_ratio'] = df_processed['city_mpg'] / (df_processed['highway_mpg'] + 0.1)\n",
        "\n",
        "# Create cylinder displacement ratio\n",
        "df_processed['displacement_per_cylinder'] = df_processed['displacement'] / (df_processed['cylinders'] + 0.1)\n",
        "\n",
        "# Create binary features for special categories\n",
        "df_processed['is_luxury'] = df_processed['make'].isin(['audi', 'bmw', 'mercedes-benz', 'porsche', 'jaguar', 'land rover', 'genesis']).astype(int)\n",
        "df_processed['is_suv'] = df_processed['class'].str.contains('suv', case=False).astype(int)\n",
        "df_processed['is_4wd'] = df_processed['drive'].str.contains('4wd|awd', case=False).astype(int)\n",
        "df_processed['is_automatic'] = df_processed['transmission'].str.contains('a', case=False).astype(int)\n",
        "\n",
        "# Create interaction features\n",
        "df_processed['displacement_year_interaction'] = df_processed['displacement'] * df_processed['year']\n",
        "df_processed['cylinders_displacement_interaction'] = df_processed['cylinders'] * df_processed['displacement']\n",
        "\n",
        "print(f\"Original features: {len(df.columns)}\")\n",
        "print(f\"After feature engineering: {len(df_processed.columns)}\")\n",
        "print(f\"New features created: {set(df_processed.columns) - set(df.columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjdecdcCdt-I",
        "outputId": "2fd24ca8-1ba0-43d8-e007-292943b6704d"
      },
      "outputs": [],
      "source": [
        "# Define target and features\n",
        "# We'll predict combination_mpg (composite fuel efficiency)\n",
        "TARGET = 'combination_mpg'\n",
        "\n",
        "# Identify features to drop (including other mpg columns to avoid data leakage)\n",
        "features_to_drop = ['combination_mpg', 'city_mpg', 'highway_mpg', 'model']\n",
        "# Dropping 'model' as it has too many unique values (would cause overfitting)\n",
        "\n",
        "# Define feature set\n",
        "X = df_processed.drop(columns=features_to_drop, errors='ignore')\n",
        "y = df_processed[TARGET]\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "print(f\"Target vector shape: {y.shape}\")\n",
        "\n",
        "# Identify numerical and categorical columns\n",
        "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(f\"\\nNumerical features ({len(numerical_features)}): {numerical_features}\")\n",
        "print(f\"\\nCategorical features ({len(categorical_features)}): {categorical_features}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5Z1esCddt-I",
        "outputId": "2386b4b3-274c-4e0b-b1ce-bdc16f295fa9"
      },
      "outputs": [],
      "source": [
        "# Split the data before any transformation to avoid data leakage\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=pd.qcut(y, q=5, labels=False)  # Stratified split for regression\n",
        ")\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Test set shape: {X_test.shape}\")\n",
        "print(f\"Training target shape: {y_train.shape}\")\n",
        "print(f\"Test target shape: {y_test.shape}\")\n",
        "\n",
        "# Save the indices for later use\n",
        "train_indices = X_train.index\n",
        "test_indices = X_test.index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YYUNVZudt-I"
      },
      "source": [
        "# **Step 3: Data Type Conversion (Encoding)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5vcDFbkdt-J",
        "outputId": "330e4efb-112a-4bd6-ba3c-fb3cc0f68eff"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Define preprocessing pipelines for different feature types\n",
        "\n",
        "# 1. Numerical features pipeline\n",
        "numerical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),  # Additional safety for any missing values\n",
        "    ('scaler', StandardScaler())  # Standard scaling for most models\n",
        "])\n",
        "\n",
        "# 2. Categorical features pipeline\n",
        "categorical_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))  # One-hot encoding\n",
        "])\n",
        "\n",
        "# 3. Create column transformer\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numerical_pipeline, numerical_features),\n",
        "    ('cat', categorical_pipeline, categorical_features)\n",
        "])\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# Get feature names after one-hot encoding\n",
        "categorical_encoder = preprocessor.named_transformers_['cat'].named_steps['encoder']\n",
        "categorical_feature_names = categorical_encoder.get_feature_names_out(categorical_features)\n",
        "all_feature_names = numerical_features + list(categorical_feature_names)\n",
        "\n",
        "print(f\"Original training features: {X_train.shape[1]}\")\n",
        "print(f\"Processed training features: {X_train_processed.shape[1]}\")\n",
        "print(f\"Number of new feature names: {len(all_feature_names)}\")\n",
        "\n",
        "# Create DataFrames for processed data\n",
        "X_train_df = pd.DataFrame(X_train_processed, columns=all_feature_names, index=train_indices)\n",
        "X_test_df = pd.DataFrame(X_test_processed, columns=all_feature_names, index=test_indices)\n",
        "\n",
        "print(f\"\\nProcessed training set shape: {X_train_df.shape}\")\n",
        "print(f\"Processed test set shape: {X_test_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQiCH8Q7dt-J"
      },
      "source": [
        "# **Step 4: Feature Engineering (Additional)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hrma07Bmdt-J",
        "outputId": "e4d646fe-72ce-40a8-e2ba-2679ecbcc847"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
        "\n",
        "# 1. Correlation with target\n",
        "print(\"Top 10 features by correlation with target:\")\n",
        "correlation_with_target = pd.DataFrame({\n",
        "    'Feature': all_feature_names[:len(numerical_features)],  # Only numerical for correlation\n",
        "    'Correlation': [np.corrcoef(X_train_df[feat], y_train)[0, 1]\n",
        "                    for feat in all_feature_names[:len(numerical_features)]]\n",
        "})\n",
        "correlation_with_target['Abs_Correlation'] = abs(correlation_with_target['Correlation'])\n",
        "top_corr_features = correlation_with_target.sort_values('Abs_Correlation', ascending=False).head(10)\n",
        "display(top_corr_features)\n",
        "\n",
        "# 2. Mutual information\n",
        "print(\"\\nTop 10 features by mutual information:\")\n",
        "mi_selector = SelectKBest(score_func=mutual_info_regression, k='all')\n",
        "mi_selector.fit(X_train_df, y_train)\n",
        "mi_scores = pd.DataFrame({\n",
        "    'Feature': all_feature_names,\n",
        "    'MI_Score': mi_selector.scores_\n",
        "})\n",
        "top_mi_features = mi_scores.sort_values('MI_Score', ascending=False).head(10)\n",
        "display(top_mi_features)\n",
        "\n",
        "# 3. Feature importance using a quick Random Forest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_df, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n